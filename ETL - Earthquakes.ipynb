{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: https://www.kaggle.com/datasets/usgs/earthquake-database"
      ],
      "metadata": {
        "id": "n4L4gsIIDILy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descarga automatica del dataset en Kaggle"
      ],
      "metadata": {
        "id": "sfP1cHJrT7nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"usgs/earthquake-database\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "eac3fGfpNstW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicio del proceso"
      ],
      "metadata": {
        "id": "VxEg7L4UUEoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qkx-yJmxuA2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_earthquakes = pd.read_csv(f\"{path}/database.csv\")\n",
        "df_earthquakes.columns = df_earthquakes.columns.str.lower().str.replace(' ','_')\n",
        "df_earthquakes['date'] = pd.to_datetime(df_earthquakes['date'], dayfirst=False, errors='coerce').dt.date\n",
        "df_earthquakes.loc[df_earthquakes[\"date\"].isna(), 'date'] = pd.to_datetime(df_earthquakes.loc[df_earthquakes[\"date\"].isna(), 'time'], errors='coerce').dt.date\n",
        "columns = ['date','latitude','longitude','type','depth','magnitude','id','source']\n",
        "df_earthquakes = df_earthquakes[columns]\n",
        "df_earthquakes.head(3)\n"
      ],
      "metadata": {
        "id": "pYD8uiTOx1fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos adicionales generados con IA a partir de los acronimos de la columna source de earthquakes"
      ],
      "metadata": {
        "id": "qCNpfX4iDFhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"source\": [\n",
        "        \"ISCGEM\", \"ISCGEMSUP\", \"OFFICIAL\", \"CI\", \"US\",\n",
        "        \"NC\", \"GCMT\", \"UW\", \"ATLAS\", \"NN\", \"SE\", \"AK\", \"PR\"\n",
        "    ],\n",
        "    \"source_name\": [\n",
        "        \"Catálogo Global de Sismos ISC-GEM\",\n",
        "        \"Catálogo Global de Sismos ISC-GEM\",\n",
        "        \"Agencia Oficial Local/Regional\",\n",
        "        \"Red Sísmica del Sur de California\",\n",
        "        \"Servicio Geológico de EE. UU. (USGS)\",\n",
        "        \"Red Sísmica del Norte de California\",\n",
        "        \"Global Centroid Moment Tensor\",\n",
        "        \"Red Sísmica del Noroeste del Pacífico\",\n",
        "        \"Catálogo Sísmico ATLAS\",\n",
        "        \"Laboratorio Sismológico de Nevada\",\n",
        "        \"Red Sísmica del Sureste de EE. UU.\",\n",
        "        \"Centro de Terremotos de Alaska\",\n",
        "        \"Red Sísmica de Puerto Rico\"\n",
        "    ],\n",
        "    \"source_description\": [\n",
        "        \"Catálogo histórico que re-analiza y estandariza datos sísmicos antiguos.\",\n",
        "        \"Catálogo histórico que re-analiza y estandariza datos sísmicos antiguos.\",\n",
        "        \"Fuente oficial del país o región donde ocurrió el sismo (genérico).\",\n",
        "        \"Colaboración entre USGS y Caltech para monitorear el sur de California.\",\n",
        "        \"Agencia principal de monitoreo sísmico a nivel mundial, especialmente para eventos recientes.\",\n",
        "        \"Colaboración entre USGS y Berkeley para monitorear el norte de California.\",\n",
        "        \"Proyecto que determina los mecanismos focales de sismos de magnitud moderada a grande.\",\n",
        "        \"Red regional de la Universidad de Washington para monitorear Washington y Oregón.\",\n",
        "        \"Un compendio o catálogo de sismos, como el 'Centennial' o proyectos de re-análisis.\",\n",
        "        \"Red sísmica regional que monitorea la actividad en Nevada y áreas circundantes.\",\n",
        "        \"Red regional que monitorea la actividad sísmica en el sureste de los Estados Unidos.\",\n",
        "        \"Red sísmica regional para el monitoreo del estado de Alaska.\",\n",
        "        \"Monitorea la actividad sísmica en la región de Puerto Rico y el Caribe.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_source = pd.DataFrame(data)\n",
        "df_source.head(3)\n"
      ],
      "metadata": {
        "id": "uVy0i-meCDxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_earthquakes = pd.merge(df_earthquakes, df_source, on='source', how='left')\n",
        "df_earthquakes.head(3)"
      ],
      "metadata": {
        "id": "M9ag--M1CjMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CREATE TABLE en Postgresql\n",
        "```\n",
        "CREATE TABLE earthquakes (\n",
        "    date DATE,\n",
        "    latitude FLOAT,\n",
        "    longitude FLOAT,\n",
        "    type VARCHAR(50),\n",
        "    depth FLOAT,\n",
        "    magnitude FLOAT,\n",
        "    id VARCHAR(50),\n",
        "    source VARCHAR(50),\n",
        "    source_name VARCHAR(100),\n",
        "    source_description VARCHAR(200)\n",
        ");\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vwb3ExRP9W3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def insert_data(df,table_name,db_host,db_port,db_name,db_user,db_password):\n",
        "  try:\n",
        "      # Crea el motor de conexión con SQLAlchemy\n",
        "      engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
        "      conn = engine.raw_connection()\n",
        "      cur = conn.cursor()\n",
        "      print(\"Conexión a PostgreSQL exitosa.\")\n",
        "\n",
        "      # Prepara un \"archivo en memoria\" para la carga masiva\n",
        "      buffer = io.StringIO()\n",
        "      # Escribe el contenido del DataFrame al buffer en formato CSV (sin cabecera ni índice)\n",
        "      df.to_csv(buffer, index=False, header=False)\n",
        "      buffer.seek(0) # Regresa al inicio del buffer para la lectura\n",
        "\n",
        "      # Ejecuta el comando COPY de PostgreSQL para una inserción masiva y eficiente\n",
        "      print(f\"Cargando {len(df)} registros en la tabla '{table_name}'...\")\n",
        "      cur.copy_expert(f\"\"\"COPY {table_name} FROM STDIN WITH (FORMAT CSV)\"\"\", buffer)\n",
        "\n",
        "      # Confirma la transacción\n",
        "      conn.commit()\n",
        "      print(\"Todos los registros han sido insertados.\")\n",
        "\n",
        "  except Exception as error:\n",
        "      print(\"Error al conectar o insertar en la base de datos:\", error)\n",
        "      if 'conn' in locals() and conn:\n",
        "          conn.rollback() # Revierte los cambios si hubo un error\n",
        "\n",
        "  finally:\n",
        "      # Cierra la conexión\n",
        "      if 'cur' in locals() and cur:\n",
        "          cur.close()\n",
        "      if 'conn' in locals() and conn:\n",
        "          conn.close()\n",
        "          print(\"Conexión a PostgreSQL cerrada.\")"
      ],
      "metadata": {
        "id": "emvu3arx-KRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En caso de problemas con el Firewall (Reglas de entrada del servidor del Postgresql) se puede obtener la ip del Google Colab con:\n",
        "\n",
        "\n",
        "```\n",
        "!curl ipecho.net/plain\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0-sNTxaTIw95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "id": "tUXd9163Ie-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "db_host = \"#COMPLETAR#\"\n",
        "db_port = \"5432\"\n",
        "db_name = \"#COMPLETAR#\"\n",
        "db_user = \"#COMPLETAR#\"\n",
        "db_password = \"#COMPLETAR#\"\n",
        "table_name = \"earthquakes\"\n",
        "\n",
        "insert_data(df_earthquakes,table_name,db_host,db_port,db_name,db_user,db_password)"
      ],
      "metadata": {
        "id": "DnclksRdFbzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsrR9xVyFm6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}